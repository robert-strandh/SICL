\chapter{Compiler}
\label{chap-compiler}

\section{Different uses of the compiler}

The compiler is used in several different situations.  There are
essentially three use cases, so it is appropriate to talk about three
different compilers:

\begin{itemize}
\item The \emph{file compiler}.  This compiler is invoked by
  \texttt{compile-file}.  It takes a \commonlisp{} source file and generates a
  file containing object code (a so-called \emph{fasl} file). 
\item The \emph{lambda expression compiler}.  This compiler is invoked
  when \texttt{compile} is called with arguments \texttt{nil} and a
  \emph{lambda expression}, and by \texttt{coerce} to convert a lambda
  expression to a function.  It compiles the lambda expression in the
  \emph{null lexical environment}.  It produces a \emph{function
    object}.
\item The \emph{top-level expression compiler}.  This compiler is
  invoked by \texttt{eval}.  It produces a function with no parameters
  which is then immediately \emph{called} by \texttt{eval}.  
\end{itemize}

In addition to these use cases, we also distinguish between different
compilers along an orthogonal dimension:

\begin{itemize}
\item A \emph{native} compiler is a compiler that produces code for
  its host \commonlisp{} system. 
\item An \emph{extrinsic} compiler is a compiler that produces code
  for a \commonlisp{} system other than its host system.  An extrinsic
  compiler is also known as a \emph{cross compiler}.
\end{itemize}

We now have potentially 6 different compilers.  Specific issues
related to cross compilation are discussed in
\refChap{chap-cross-compilation}. 

\section{Compilation phases}

\subsection{Read (file compiler)}

If the file compiler is used, then the first thing that happens is
that a top-level form is \emph{read} from a file stream.  The result
of this phase is a data structure representing the form in the usual
way. 

In addition to the internal data structure, the reader also supplies
information about \emph{source location} of each form.  

\subsection{Convert to abstract syntax tree}

\subsubsection{Processing of top-level forms}

The \hs{} requires the file compiler to process top-level forms in a
special way.%
\footnote{See section 3.2.3.1 in the \hs{}.}
As part of this processing, the compiler might call \texttt{eval} to
evaluate forms in the \emph{evaluation environment} of the
compilation. 

\subsubsection{Conversion}

A top-level form that is required to be compiled is then converted
into an abstract syntax tree.  This is done in the usual way, by
traversing the form while accessing a \emph{syntactic environment}
which determines what different types of expressions mean,
i.e. whether a variable is really a symbol-macro, and whether a
compound expression is a function call, a macro call, or a special
form.  In this step, macros and symbol macros are expanded, and nodes
the abstract syntax tree are created as
appropriate. \seechap{chap-abstract-syntax-tree} References to
variables are replaced by nodes so that the name of a variable no
longer influences its scope.

\subsubsection{Inlining}

As part of this phase, a \emph{function call form} might be replaced
by the body of the function that is called.  Whether this
transformation happens or not depends on several factors:

\begin{itemize}
\item The abstract syntax tree of the called function must be
  available.  In general, this will be the case when an
  \texttt{inline} declaration was in effect when the function was
  defined.  But it could also be the case that the abstract syntax
  tree was explicitly removed, for instance as part of the delivery of
  commercial code. 
\item As required by the \hs{}, there must not be a \texttt{notinline}
  declaration of the function in effect when the function call form is
  encountered.
\item In \sysname{} we also require that there be an \texttt{inline}
  declaration in effect when function call form is encountered.
\end{itemize}

The reason inlining is done this early is that the code that is
generated may depend on the \emph{context} in which a form is
evaluated, and in particular how many \emph{values} are required.  

\subsection{Convert to medium-level intermediate representation}

In the next phase, the abstract syntax tree is converted into a
\emph{flowchart}, which is a particular kind of \emph{graph} with two
kinds of nodes (\emph{instruction nodes} and \emph{data nodes}) and
two kinds of edges (\emph{control-flow edges} and \emph{data-flow
  edges}).  For details on this representation, see
\refChap{chap-mir}.

\subsection{Convert to SSA form}

\subsection{Optimization}

\subsection{Register allocation}

For register allocation, we use the traditional \emph{graph coloring}
method.  Since this problem is intractable, we use the method describe
in \cite{Muchnick:1998:ACD:286076}.  This method uses two rules:

\begin{enumerate}
\item The first rule consists of removing a node N in the graph that
  has a degree that is less than the number of available colors
  (registers), and solving the reduced problem.  The node color chosen
  for N is any color not chosen by a node adjacent to N.
\item The second rule consists of removing a node N in the graph with
  the smallest degree that is greater than or equal to the number of
  available colors, and solving the reduced problem.  With some luck,
  two or more nodes adjacent to N are assigned the same color so that
  the total number of colors used by the adjacent nodes is less than
  the number of available colors, leaving at least one color for N.
\end{enumerate}

We modified the standard algorithm to allow for variables to have a
\emph{required register}, so that either the required register gets
assigned to the variable, or the variable is spilled.  This technique
is used for variables that are used to hold \emph{callee-saved}
registers to avoid that one such register gets assigned to another.
We also allow for a variable to have a \emph{preferred register} which
is chosen by the register allocator if it is available at the time a
choice has to be made.  We use this technique to try as much as
possible to compute a value into a register that it is required to end
up in eventually, such as a register for a particular argument.5
\fixme{Document how we indicate that an instruction might trash a
  register.  Also, attempt to use the same method to indicate that a
  global function or variable value might change across a function
  call.}

\subsection{Code generation} 

\section{Optimization}

\subsection{Type inference}

Type inference in the \sysname{} compiler is implemented as a
\emph{forward data-flow problem} on the flowchart.  Each \emph{arc} in
the flowchart contains a \emph{type descriptor} for each variable in
the program.  A type descriptor is a canonical representation of the
disjunction of a large number of mutually disjoint types.  

Each instruction type influences the possible types of its output as a
function of the types of its inputs.  In particular, the
\texttt{typeq} instruction takes the type of its input and a constant
type and computes the \emph{set intersection}
between the two in one successor arc and the \emph{set difference} in
the other successor arc.  

Initially, every type descriptor for every variable represents the
type T.  Then, the influence of each instruction is applied until
a fixpoint is obtained.  If any variable has the type \texttt{NIL} on
some arc, then that arc represents an impossible transition and it can
be removed. 

Type descriptors represent not only \commonlisp{} types, but also types such
as \emph{raw pointer}, \emph{unboxed floats}, etc.  The type
information computed by the type inference phase is stored in the
\emph{code object} for use by the garbage collector, but also by tools
such as debuggers and inspectors. 

\subsection{Access to special variables and global functions}

To access a special variable, the code must first search the dynamic
environment in case a per-thread binding exists.  If such a binding
exists, a tagged pointer of type CONS is returned, but the pointer
refers to an entry on the stack; a dynamic value cell.  If no such
binding exists, the global value cell is returned.

In general, for every access to a special variable, the value cell
must be searched for first.  There are many cases, however, where the
compiler can detect that multiple accesses to some special variable
must refer to the same value cell.  In that case, the (pointer to the)
value cell is a candidate for register allocation, and computing it is
loop invariant. 

When it comes to the \emph{contents} of the value cell, however, the
situation is more complicated because of the possibility that multiple
threads might access the (global) value cell concurrently.  In fact,
this is a common situation when a global variable is used for
synchronization purposes.

When some function accesses a special variable multiple times, it
might seem required to read the contents of the value cell for each
such access, even though the compiler can prove that the same cell is
involved in each access.  However, this turns out not to be the case.
If none of the accesses are part of a loop and there is no externally
detectable activity between accesses (no assignment to a global
variable, no function call), then there is always a possible scenario
according to which the same value will be obtained in all the
accesses.  In such cases, not only the value cell, but also the value
itself is a candidate for register allocation.  Even if accesses are
part of a loop, in some cases the value can be cached in a register.
The necessary condition for such register allocation is that the loop
provably \emph{terminates} and that there is no externally detectable
activity between consecutive accesses. 

The situation for global functions is similar to that of special
variables, except simpler since no special binding can exist for such
accesses.  While it is not very probable that anyone attempts to use
global functions for synchronization purposes, this can not be
excluded either.  An exception to the rule is when the global function
is a standard \commonlisp{} function, in which case it can not be replaced, so
it is safe to cache the function in a register. 

\subsection{Access to array elements}

When an array has not been declared to be \texttt{simple} it might
seem like every access to an array element would require locking to
prevent a different thread from adjusting the array between the time
the \emph{length} is determined and the time the element is accessed.

However, in \sysname{} the rack of an array is always
\emph{internally consistent} in that the \emph{length} information
accurately reflects the number of elements.  When an array is
adjusted, a different rack is allocated, and the new
rack is put in place in a single memory store operation.
Therefore, when the elements of an array are processed in some way,
the compiler might access the rack only once and cache it
in a register.  This optimization is possible even in a loop, as long
as the compiler can prove that the loop eventually terminates, and as
long as there is no externally detectable activity between the
accesses. 

\subsection{Access to slots of standard objects}

\section{Random thoughts}

The compiler should be as portable as possible.  It should use
portable Common Lisp for as many of the passes as possible.  

The compiler should keep information about which registers are live,
and how values are represented in live registers, for all values of
the program counter.  This information is used by the garbage
collector to determine what registers should be scanned, and how.   It
is also used by the debugger.  

The compiler should do some extensive type inferencing.  It should be
able to eliminate code for which the result of executing it is known
as a result of the contents of the compilation environment.  


%%  LocalWords:  disjunction
